{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of baseline using Artificial Neural Network with Original + Win-loss + feature vectors feature set and BL"
      ],
      "metadata": {
        "id": "zmHMuvgB5voq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary files: logistic_regression_functions.py, ann_functions.py, testing_functions.py, win_loss_functions.py, feature_vectors_functions, BL_17.csv, BL_18.csv, BL_19.csv, A_BL.csv, H_BL.csv, A_BL_before_threshold.csv, H_BL_before_threshold.csv"
      ],
      "metadata": {
        "id": "fnGbA8u0eSPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXdTb_8WroRp"
      },
      "outputs": [],
      "source": [
        "import logistic_regression_functions\n",
        "import ann_functions\n",
        "import testing_functions\n",
        "import win_loss_functions\n",
        "import feature_vectors_functions\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline is implemented according to the paper An Improved Prediction System for Football a Match Result bu C. P. Igiri and E. O. Nwachukwu from 2014. The original features as described in the paper are used and the model is evaluated on the BL dataset."
      ],
      "metadata": {
        "id": "91YkXBVn57cJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authors used only one season for training, so I did the same. I used seasons 2016/17 for training season 2017/18 as validation set and the second half of season 2018/19 for testing. The validation set is used to select the best checkpoint of the training according to the validation accuracy."
      ],
      "metadata": {
        "id": "oF6VWY7c6GlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_win_loss, y_train = win_loss_functions.create_data(['BL_17.csv'], skip_rounds = 6, return_names=True)\n",
        "results_val_win_loss, matches_per_round = win_loss_functions.create_data_single('BL_18.csv', ['BL_17.csv'], skip_rounds = 6, return_names=True)\n",
        "# Dates are returned as well for dividing testing season into slices\n",
        "results_test_win_loss, matches_per_round = win_loss_functions.create_data_single('BL_19.csv', ['BL_17.csv', 'BL_18.csv'],\n",
        "                                return_dates=True, skip_rounds = 6, return_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2LRsdfUr-Wr",
        "outputId": "17dea373-cec2-4a9e-cf15-f836554812db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BL_17.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_train_originals, matches_per_round = ann_functions.create_data_single('BL_17.csv', 19, 17,\n",
        "                                   logistic_regression_functions.team_names_map_bl,\n",
        "                                   logistic_regression_functions.secondary_team_names_map_bl)\n",
        "results_val_originals, matches_per_round = ann_functions.create_data_single('BL_18.csv', 19, 18,\n",
        "                                  logistic_regression_functions.team_names_map_bl,\n",
        "                                  logistic_regression_functions.secondary_team_names_map_bl)\n",
        "# Dates are returned as well for dividing testing season into slices\n",
        "results_test_originals, matches_per_round = ann_functions.create_data_single('BL_19.csv', 19, 19,\n",
        "                                  logistic_regression_functions.team_names_map_bl,\n",
        "                                  logistic_regression_functions.secondary_team_names_map_bl,\n",
        "                                  return_dates=True)\n",
        "X_train_originals = results_train_originals.drop('FTR', axis=1)\n",
        "y_train_originals = results_train_originals['FTR']"
      ],
      "metadata": {
        "id": "zXbGVVw7smVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating the two feature sets together\n",
        "X_train_mix = pd.concat([X_train_originals, X_train_win_loss], axis=1)\n",
        "results_val_mix = pd.concat([results_val_originals, results_val_win_loss], axis=1)\n",
        "results_test_mix = pd.concat([results_test_originals, results_test_win_loss], axis=1)\n",
        "X_train_mix = X_train_mix.loc[:,~X_train_mix.columns.duplicated()].copy()\n",
        "results_val_mix = results_val_mix.loc[:,~results_val_mix.columns.duplicated()].copy()\n",
        "results_test_mix = results_test_mix.loc[:,~results_test_mix.columns.duplicated()].copy()"
      ],
      "metadata": {
        "id": "G8177rdAs7EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = pd.read_csv('A_BL.csv')\n",
        "H = pd.read_csv('H_BL.csv')\n",
        "A_before_threshold = pd.read_csv('A_BL_before_threshold.csv')\n",
        "H_before_threshold = pd.read_csv('H_BL_before_threshold.csv')"
      ],
      "metadata": {
        "id": "vzAdCcH0s_-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the feature vectors to the features\n",
        "X_train = feature_vectors_functions.add_feature_vector(X_train_mix, A, H)\n",
        "results_val = feature_vectors_functions.add_feature_vector(results_val_mix, A, H)\n",
        "results_test = feature_vectors_functions.add_feature_vector(results_test_mix, A, H)"
      ],
      "metadata": {
        "id": "msfYFaLgtKyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']\n",
        "# The classes need to go from 0 to 2 not from -1 to 1.\n",
        "y_train += 1\n",
        "y_val += 1"
      ],
      "metadata": {
        "id": "H82AqgpytNTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "They didnt say what ANN architecture they used. I used 3 dense layers with 64, 32 and 16 neurons. I used dropout to overcome overfitting."
      ],
      "metadata": {
        "id": "m_pYLKYw7Fsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I always let the model train for 100 epochs and took the weights from the best epoch according to validation accuracy."
      ],
      "metadata": {
        "id": "-bO_8aKK7PR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use all the data available, the first half of the testing season was added to the training data."
      ],
      "metadata": {
        "id": "bBYkuE0P7Sqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 11 * matches_per_round"
      ],
      "metadata": {
        "id": "RuhWq9n_O2k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)\n",
        "y_test_to_append += 1"
      ],
      "metadata": {
        "id": "1PX-akeHueNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in tqdm(slices):\n",
        "  # Creating the model\n",
        "  model = ann_functions.func_model((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "  mc = tf.keras.callbacks.ModelCheckpoint('./weights_model.h5',\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  y_test += 1\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose = 0,\n",
        "                    callbacks=[mc])\n",
        "  # Load the best checkpoint\n",
        "  model.load_weights('weights_model.h5')\n",
        "  weighted_sum += (model.evaluate(X_test, y_test)[1] * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print('')\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjUT484pt2l6",
        "outputId": "03196516-c13a-459f-d5c7-5eec104a6b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.9564 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:21<04:14, 21.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9792 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:38<03:29, 19.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2768 - accuracy: 0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [00:59<03:20, 20.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8429 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [01:21<03:04, 20.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8291 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [01:42<02:46, 20.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7776 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [02:03<02:26, 20.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8406 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [02:21<01:59, 19.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0022 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [02:39<01:36, 19.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8219 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [03:00<01:19, 19.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7699 - accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [03:19<00:58, 19.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7066 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [03:40<00:39, 19.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1687 - accuracy: 0.4118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [04:01<00:20, 20.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0853 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:20<00:00, 20.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.5686274640310823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 56.86%."
      ],
      "metadata": {
        "id": "uLAdgFjH8x85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting with feature vectors extracted before applying the threshold."
      ],
      "metadata": {
        "id": "-RDTJuMt9cA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train was changed, load it again\n",
        "X_train_win_loss, y_train = win_loss_functions.create_data(['BL_17.csv'], skip_rounds = 6, return_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQySNJygguUM",
        "outputId": "5b88695b-08c3-4edb-878f-7494512a43ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BL_17.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the feature vectors to the features\n",
        "X_train = feature_vectors_functions.add_feature_vector(X_train_mix, A_before_threshold, H_before_threshold)\n",
        "results_val = feature_vectors_functions.add_feature_vector(results_val_mix, A_before_threshold, H_before_threshold)\n",
        "results_test = feature_vectors_functions.add_feature_vector(results_test_mix, A_before_threshold, H_before_threshold)"
      ],
      "metadata": {
        "id": "wzrpfRF_g8sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']\n",
        "# The classes need to go from 0 to 2 not from -1 to 1.\n",
        "y_train += 1\n",
        "y_val += 1"
      ],
      "metadata": {
        "id": "evXcAnDHg_Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 11 * matches_per_round"
      ],
      "metadata": {
        "id": "YG0zQ-UyhIHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)\n",
        "y_test_to_append += 1"
      ],
      "metadata": {
        "id": "u3DrvUWPvzJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in tqdm(slices):\n",
        "  # Creating the model\n",
        "  model = ann_functions.func_model((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "  mc = tf.keras.callbacks.ModelCheckpoint('./weights_model.h5',\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  y_test += 1\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose = 0,\n",
        "                    callbacks=[mc])\n",
        "  # Load the best checkpoint\n",
        "  model.load_weights('weights_model.h5')\n",
        "  weighted_sum += (model.evaluate(X_test, y_test)[1] * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print('')\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbdNNiwbhCJv",
        "outputId": "39f51cce-3d8c-48fd-9ee8-725ba1a72444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0002 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:15<03:05, 15.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 0.9294 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:36<03:27, 18.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0581 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [00:58<03:19, 19.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2317 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [01:19<03:04, 20.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7699 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [01:35<02:32, 19.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6502 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [01:56<02:18, 19.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8373 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [02:13<01:52, 18.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9413 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [02:30<01:30, 18.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.8367 - accuracy: 0.6429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [02:51<01:16, 19.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6637 - accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [03:12<00:59, 19.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7999 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [03:33<00:40, 20.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 1.1501 - accuracy: 0.2941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [03:52<00:19, 19.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0741 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:10<00:00, 19.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.5686274599405675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 56.86%."
      ],
      "metadata": {
        "id": "KtCmMOyp801H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting with feature vectors including home feature vectors for the away teams and away feature vectors for the home teams."
      ],
      "metadata": {
        "id": "OUJw0XRG9m9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train was changed, load it again\n",
        "X_train_win_loss, y_train = win_loss_functions.create_data(['BL_17.csv'], skip_rounds = 6, return_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw2Kx9Ja43DB",
        "outputId": "6cc704d8-654c-4ff7-e54a-c4ac3fc217d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BL_17.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the feature vectors to the features\n",
        "X_train = feature_vectors_functions.add_feature_vector(X_train_mix, A, H, include_all=True)\n",
        "results_val = feature_vectors_functions.add_feature_vector(results_val_mix, A, H, include_all=True)\n",
        "results_test = feature_vectors_functions.add_feature_vector(results_test_mix, A, H, include_all=True)"
      ],
      "metadata": {
        "id": "QXMkSz5s4600"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']\n",
        "# The classes need to go from 0 to 2 not from -1 to 1.\n",
        "y_train += 1\n",
        "y_val += 1"
      ],
      "metadata": {
        "id": "BesXObRZ4-tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 11 * matches_per_round"
      ],
      "metadata": {
        "id": "t4BrpQzdhK2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)\n",
        "y_test_to_append += 1"
      ],
      "metadata": {
        "id": "xfodH7lev0Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in tqdm(slices):\n",
        "  # Creating the model\n",
        "  model = ann_functions.func_model((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "  mc = tf.keras.callbacks.ModelCheckpoint('./weights_model.h5',\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  y_test += 1\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose = 0,\n",
        "                    callbacks=[mc])\n",
        "  # Load the best checkpoint\n",
        "  model.load_weights('weights_model.h5')\n",
        "  weighted_sum += (model.evaluate(X_test, y_test)[1] * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print('')\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKugrFw5CIB",
        "outputId": "d1a92afc-f695-4abd-e625-971692b58d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7870 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:21<04:14, 21.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9697 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:42<03:53, 21.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 1.3121 - accuracy: 0.3636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [01:03<03:31, 21.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 1.2902 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [01:24<03:10, 21.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7619 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [01:46<02:50, 21.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6582 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [02:07<02:29, 21.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.9182 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [02:23<01:58, 19.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9262 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [02:40<01:32, 18.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9982 - accuracy: 0.6429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [03:01<01:17, 19.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7619 - accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [03:18<00:56, 18.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9063 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [03:36<00:36, 18.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0397 - accuracy: 0.4706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [03:54<00:18, 18.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.9643 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:12<00:00, 19.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.5620915133968677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 56.21%."
      ],
      "metadata": {
        "id": "TYcnvZf5828m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenting with feature vectors extracted before applying the threshold and including home feature vectors for the away teams and away feature vectors for the home teams."
      ],
      "metadata": {
        "id": "gC4AKvTO9vkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train was changed, load it again\n",
        "X_train_win_loss, y_train = win_loss_functions.create_data(['BL_17.csv'], skip_rounds = 6, return_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvoAzbhp0U4U",
        "outputId": "64abe63a-0187-4ee0-e670-eb8c3da50a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BL_17.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the feature vectors to the features\n",
        "X_train = feature_vectors_functions.add_feature_vector(X_train_mix, A_before_threshold, H, include_all=True)\n",
        "results_val = feature_vectors_functions.add_feature_vector(results_val_mix, A_before_threshold, H_before_threshold, include_all=True)\n",
        "results_test = feature_vectors_functions.add_feature_vector(results_test_mix, A_before_threshold, H_before_threshold, include_all=True)"
      ],
      "metadata": {
        "id": "F4b4lLCZ0aVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']\n",
        "# The classes need to go from 0 to 2 not from -1 to 1.\n",
        "y_train += 1\n",
        "y_val += 1"
      ],
      "metadata": {
        "id": "vXZyVOqc0dTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 11 * matches_per_round"
      ],
      "metadata": {
        "id": "NMHaD1iLhMWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)\n",
        "y_test_to_append += 1"
      ],
      "metadata": {
        "id": "aZAB8s_rv1WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in tqdm(slices):\n",
        "  # Creating the model\n",
        "  model = ann_functions.func_model((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "  mc = tf.keras.callbacks.ModelCheckpoint('./weights_model.h5',\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  y_test += 1\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose = 0,\n",
        "                    callbacks=[mc])\n",
        "  # Load the best checkpoint\n",
        "  model.load_weights('weights_model.h5')\n",
        "  weighted_sum += (model.evaluate(X_test, y_test)[1] * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print('')\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnGIQqzy0fHq",
        "outputId": "7a5d2240-aa9d-44ad-b3f2-c5d1e872e955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8166 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:15<03:08, 15.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.9356 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:31<02:52, 15.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1619 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [00:47<02:37, 15.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.1751 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [01:08<02:40, 17.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9444 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [01:29<02:32, 19.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7572 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [01:50<02:18, 19.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.9768 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [02:07<01:53, 18.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8144 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [02:29<01:38, 19.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7578 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [02:50<01:20, 20.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0218 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [03:07<00:57, 19.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6999 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [03:29<00:39, 19.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1641 - accuracy: 0.4118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [03:47<00:19, 19.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.9838 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:08<00:00, 19.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.5686274611092861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 56.86%."
      ],
      "metadata": {
        "id": "GFtFHu23856v"
      }
    }
  ]
}