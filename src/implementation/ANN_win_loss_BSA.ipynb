{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of baseline using Artificial Neural Network with Win-loss feature set and BSA"
      ],
      "metadata": {
        "id": "akf57VLaShSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary files: ann_functions.py, testing_functions.py, win_loss_functions.py, BRA.csv"
      ],
      "metadata": {
        "id": "Fcd5tOmLcd8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu-YSdWVT0C1"
      },
      "outputs": [],
      "source": [
        "import ann_functions\n",
        "import testing_functions\n",
        "import win_loss_functions\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline is implemented according to the paper An Improved Prediction System for Football a Match Result bu C. P. Igiri and E. O. Nwachukwu from 2014. The features based only on results of previous matches are used and the model is evaluated on the BSA dataset."
      ],
      "metadata": {
        "id": "2XVVetRwSqLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authors used only one season for training, so I did the same. I used seasons 2017 for training season 2018 as validation set and the second half of season 2019 for testing. The validation set is used to select the best checkpoint of the training according to the validation accuracy."
      ],
      "metadata": {
        "id": "npUvUyiVSv9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = pd.read_csv('BRA.csv')\n",
        "full_dataset.rename(columns = {'Home':'HomeTeam', 'Away': 'AwayTeam',\n",
        "                               'HG': 'FTHG', 'AG': 'FTAG', 'Res': 'FTR',\n",
        "                               'PH': 'B365H', 'PD': 'B365D',\n",
        "                               'PA': 'B365A'}, inplace = True)\n",
        "for season in full_dataset['Season'].unique():\n",
        "  dataset = full_dataset[full_dataset['Season'] == season]\n",
        "  dataset.to_csv('BSA_' + str(season)[-2:] + '.csv', index=False)"
      ],
      "metadata": {
        "id": "HtQb-a5heHEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = win_loss_functions.create_data(['BSA_17.csv'], skip_rounds = 6)\n",
        "results_val, matches_per_round = win_loss_functions.create_data_single('BSA_18.csv', ['BSA_17.csv'], skip_rounds = 6)\n",
        "# Dates are returned as well for dividing testing season into slices\n",
        "results_test, matches_per_round = win_loss_functions.create_data_single('BSA_19.csv', ['BSA_17.csv', 'BSA_18.csv'],\n",
        "                                return_dates=True, skip_rounds = 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgw8_ATrWSM9",
        "outputId": "da2b9f99-a9d6-403e-a574-5583f757b46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BSA_17.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']\n",
        "# The classes need to go from 0 to 2 not from -1 to 1.\n",
        "y_train += 1\n",
        "y_val += 1"
      ],
      "metadata": {
        "id": "qg1gOtmLWksK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "They didnt say what ANN architecture they used. I used 3 dense layers with 64, 32 and 16 neurons. I used dropout to overcome overfitting."
      ],
      "metadata": {
        "id": "EJJ4OD4FTFSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I always let the model train for 100 epochs and took the weights from the best epoch according to validation accuracy."
      ],
      "metadata": {
        "id": "xMvb0nd-TIag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use all the data available, the first half of the testing season was added to the training data."
      ],
      "metadata": {
        "id": "bwyLB9LlTL3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 13 * matches_per_round"
      ],
      "metadata": {
        "id": "bJVVBs-gRSqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)\n",
        "y_test_to_append += 1"
      ],
      "metadata": {
        "id": "2V5B1l6sRT85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For evaluation on the testing dataset I divided the testing data into rounds approximately. The model is trained on the training dataset, then it is evaluated on one round of the testing dataset and this round is added to the training dataset."
      ],
      "metadata": {
        "id": "CsDQXOpYTS-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in tqdm(slices):\n",
        "  # Creating the model\n",
        "  model = ann_functions.func_model((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "  mc = tf.keras.callbacks.ModelCheckpoint('./weights_model.h5',\n",
        "                                     monitor='val_accuracy',\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  y_test += 1\n",
        "  # Train the model\n",
        "  history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=8,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose = 0,\n",
        "                    callbacks=[mc])\n",
        "  # Load the best checkpoint\n",
        "  model.load_weights('weights_model.h5')\n",
        "  weighted_sum += (model.evaluate(X_test, y_test)[1] * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print('')\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgcWHD8fXuiH",
        "outputId": "b03b9774-a8e4-4a92-c4d0-6167d290ba7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/14 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 144ms/step - loss: 1.0634 - accuracy: 0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/14 [00:18<03:56, 18.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 143ms/step - loss: 1.0011 - accuracy: 0.5714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 2/14 [00:39<04:00, 20.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 135ms/step - loss: 1.1033 - accuracy: 0.2667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 3/14 [00:58<03:33, 19.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 154ms/step - loss: 1.0257 - accuracy: 0.5833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 4/14 [01:19<03:22, 20.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step - loss: 1.0562 - accuracy: 0.4706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 5/14 [01:41<03:05, 20.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 153ms/step - loss: 1.1975 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 6/14 [02:02<02:47, 20.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step - loss: 0.9930 - accuracy: 0.5385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 7/14 [02:22<02:23, 20.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step - loss: 0.8448 - accuracy: 0.6471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 8/14 [02:44<02:05, 20.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 143ms/step - loss: 1.2490 - accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 9/14 [03:04<01:43, 20.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step - loss: 1.0141 - accuracy: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 10/14 [03:25<01:23, 20.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 143ms/step - loss: 1.0805 - accuracy: 0.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 11/14 [03:46<01:02, 20.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 162ms/step - loss: 0.9989 - accuracy: 0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 12/14 [04:07<00:42, 21.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step - loss: 1.0310 - accuracy: 0.3846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 13/14 [04:49<00:27, 27.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step - loss: 0.9964 - accuracy: 0.4706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [05:11<00:00, 22.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0.47368422025128415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 47.37%."
      ],
      "metadata": {
        "id": "TpeZu1-LT8wy"
      }
    }
  ]
}