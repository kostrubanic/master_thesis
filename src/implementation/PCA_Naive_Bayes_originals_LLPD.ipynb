{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of baseline using PCA and Naive Bayes with Original feature set and LLPD"
      ],
      "metadata": {
        "id": "PyjBy6zKqZSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary files: testing_functions.py, pca_nb_functions.py, LLPD_06.csv, LLPD_07.csv, ..., LLPD_19.csv"
      ],
      "metadata": {
        "id": "So7O_QcDniCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujVIaxZRwPAr"
      },
      "outputs": [],
      "source": [
        "import testing_functions\n",
        "import pca_nb_functions\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline is implemented according to the paper Predicting The Dutch Football Competition Using Public Data: A Machine Learning Approach by N. Tax and Y. Joustra from 2015. The original features as described in the paper are used and the model is evaluated on the LLPD dataset."
      ],
      "metadata": {
        "id": "6HAHpDT3qgsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authors used data from 13 seasons, so I used data from 13 seasons as well. I used seasons from 2006/07 to 2016/17 for training, season 2017/18 for validation and the second half of season 2018/19 for testing. Here the validation part is not necessary, but I wanted to keep the split of the dataset as similar as possible with other baselines and models."
      ],
      "metadata": {
        "id": "fg3HO8cbqpxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = pca_nb_functions.create_data(['LLPD_17.csv', 'LLPD_16.csv',\n",
        "                             'LLPD_15.csv', 'LLPD_14.csv', 'LLPD_13.csv',\n",
        "                             'LLPD_12.csv', 'LLPD_11.csv', 'LLPD_10.csv',\n",
        "                             'LLPD_09.csv', 'LLPD_08.csv',\n",
        "                                'LLPD_07.csv',\n",
        "                                'LLPD_06.csv'], pca_nb_functions.teams_llpd)\n",
        "results_val, matches_per_round = pca_nb_functions.create_data_single('LLPD_18.csv', 'LLPD_17.csv',\n",
        "                            ['LLPD_16.csv',\n",
        "                             'LLPD_15.csv', 'LLPD_14.csv', 'LLPD_13.csv',\n",
        "                             'LLPD_12.csv', 'LLPD_11.csv', 'LLPD_10.csv',\n",
        "                             'LLPD_09.csv', 'LLPD_08.csv', 'LLPD_07.csv',\n",
        "                             'LLPD_06.csv'], pca_nb_functions.teams_llpd)\n",
        "# Dates are returned as well for dividing testing season into slices\n",
        "results_test, matches_per_round = pca_nb_functions.create_data_single('LLPD_19.csv', 'LLPD_18.csv',\n",
        "                            ['LLPD_17.csv', 'LLPD_16.csv',\n",
        "                             'LLPD_15.csv', 'LLPD_14.csv', 'LLPD_13.csv',\n",
        "                             'LLPD_12.csv', 'LLPD_11.csv', 'LLPD_10.csv',\n",
        "                             'LLPD_09.csv', 'LLPD_08.csv', 'LLPD_07.csv',\n",
        "                             'LLPD_06.csv'], pca_nb_functions.teams_llpd,\n",
        "                             return_dates=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztg2TKK71FlN",
        "outputId": "033245d0-b7ce-42e8-814e-b8b83ed4b3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing LLPD_17.csv season file.\n",
            "Processing LLPD_16.csv season file.\n",
            "Processing LLPD_15.csv season file.\n",
            "Processing LLPD_14.csv season file.\n",
            "Processing LLPD_13.csv season file.\n",
            "Processing LLPD_12.csv season file.\n",
            "Processing LLPD_11.csv season file.\n",
            "Processing LLPD_10.csv season file.\n",
            "Processing LLPD_09.csv season file.\n",
            "Processing LLPD_08.csv season file.\n",
            "Processing LLPD_07.csv season file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = results_val.drop('FTR', axis=1)\n",
        "y_val = results_val['FTR']"
      ],
      "metadata": {
        "id": "NYf-_Q325QQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the paper the highest accuracy was achieved with 3 PCA components. So I used 3 components as well."
      ],
      "metadata": {
        "id": "NYlAroqsq1OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use all the data available, the validation season and the first half of the testing season was added to the training data."
      ],
      "metadata": {
        "id": "9Wa0-2pcq8nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rounds in the beginning are ignored, this is the correct index\n",
        "# of the start of the second half of the season\n",
        "start_test_index = 13 * matches_per_round"
      ],
      "metadata": {
        "id": "UOEd7BVeltSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_to_append, y_test_to_append = testing_functions.prepare_test_to_append(results_test,\n",
        "                                                                              start_test_index)"
      ],
      "metadata": {
        "id": "uFQW_dY_lvxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For evaluation on the testing dataset I divided the testing data into rounds approximately. The model is trained on the training dataset, then it is evaluated on one round of the testing dataset and this round is added to the training dataset.\n"
      ],
      "metadata": {
        "id": "hDUVOuCarDyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding validation season and 1st half of testing season to the training data\n",
        "X_train = pd.concat([X_train, X_val, X_test_to_append])\n",
        "y_train = pd.concat([y_train, y_val, y_test_to_append])\n",
        "# Rounds of the testing dataset\n",
        "slices = testing_functions.get_slices(results_test, matches_per_round,\n",
        "                                      start_test_index)\n",
        "weighted_sum = 0\n",
        "sum = 0\n",
        "for slc in slices:\n",
        "  pca = PCA(n_components=3)\n",
        "  X_train_pca = pca.fit_transform(X_train)\n",
        "  clf = GaussianNB().fit(X_train_pca, y_train)\n",
        "  X_test = slc.drop(['FTR', 'Date'], axis=1)\n",
        "  y_test = slc['FTR']\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "  weighted_sum += (clf.score(X_test_pca, y_test) * len(y_test))\n",
        "  sum += len(y_test)\n",
        "  # Add the round to the training dataset\n",
        "  X_train = pd.concat([X_train, X_test])\n",
        "  y_train = pd.concat([y_train, y_test])\n",
        "print(weighted_sum / sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ztlr8QT5Ueg",
        "outputId": "104785c3-f122-40e7-add3-54ae3e2a0443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48947368421052634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing accuracy is 48.95%"
      ],
      "metadata": {
        "id": "HXT27d16rTl5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUy2fS0a8jvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}